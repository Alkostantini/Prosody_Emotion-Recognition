{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align: center; font-size: 36px; color: #3498db; font-weight: bold;\">Prosody </h1>\n",
    "## <h2 style=\"text-align: center; font-size: 28px; color: #2ecc71; font-weight: bold;\">Prosody Active Emotion</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Library\n",
    "##############\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pyaudio\n",
    "import wave\n",
    "import tensorflow as tf \n",
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.effects\n",
    "from joblib import Parallel, delayed\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from playsound import playsound\n",
    "from datetime import datetime, timezone\n",
    "from tkinter import messagebox, Checkbutton, Radiobutton\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original audio loaded from C:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\Database\\happy_matthias_1-1 copy 2.wav\n",
      "Audio data shape: (132300,)\n",
      "Sample rate: 44100\n",
      "Reconstructed audio saved to reconstructed_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "# Step 1: Load the audio file\n",
    "input_audio_path = r'C:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\Database\\happy_matthias_1-1 copy 2.wav'  # Replace with your actual audio file path\n",
    "raw_data, sample_rate = librosa.load(input_audio_path, sr=None)\n",
    "\n",
    "# Step 2: Optionally process the raw audio data\n",
    "# Example: Normalize the audio data (optional)\n",
    "normalized_data = raw_data / np.max(np.abs(raw_data))\n",
    "\n",
    "# Step 3: Write the raw audio data back to a new file to reconstruct the voice\n",
    "output_audio_path = 'reconstructed_audio.wav'\n",
    "sf.write(output_audio_path, raw_data, sample_rate)\n",
    "\n",
    "print(f'Original audio loaded from {input_audio_path}')\n",
    "print(f'Audio data shape: {raw_data.shape}')\n",
    "print(f'Sample rate: {sample_rate}')\n",
    "print(f'Reconstructed audio saved to {output_audio_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02002635, 0.02272727, 0.02239789, ..., 0.24321476, 0.17305665,\n",
       "       0.11021081], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00927734, 0.01052856, 0.01037598, ..., 0.1126709 , 0.08016968,\n",
       "       0.05105591], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Cloud Folder\n",
    "import os \n",
    "if not os.path.exists(\"Models\"):\n",
    "    import gdown\n",
    "    folder_url =r\"https://drive.google.com/drive/folders/1EZL6Ejoa5GH8DzoZcjvRAonlgWznEh14?usp=drive_link\" \n",
    "    gdown.download_folder(folder_url)\n",
    "##########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosody Model has been loaded\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# loding the model, weights, scaler and encoder\n",
    "###############################################\n",
    "\n",
    "#prosody_model = tf.keras.models.load_model(r'./Models/Prosody_Active_Model_0.keras')\n",
    "prosody_model = tf.keras.models.load_model(r'./Models/Prosody_Model.keras')\n",
    "\n",
    "print (\"Prosody Model has been loaded\")\n",
    "\n",
    "# loding the Scaler\n",
    "with open(r\"./Models/Prosody_Scaler.pickle\", 'rb') as f:\n",
    "    prosody_scaler = pickle.load(f)\n",
    "\n",
    "# loding the Encoder    \n",
    "with open(r\"./Models/Prosody_Encoder.pickle\", 'rb') as f:\n",
    "    prosody_encoder = pickle.load(f)\n",
    "\n",
    "global PREDICTED_CLASS     \n",
    "OUTPUT_FILE=r\"./Output/input_voice.wav\"\n",
    "Output_folder= r\"./Output\"\n",
    "if not os.path.exists(Output_folder):    \n",
    "    os.makedirs(Output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alkostantini\\anaconda3\\envs\\kali\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k7i6h5qn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁</td></tr><tr><td>batch/batch_step</td><td>▁</td></tr><tr><td>batch/learning_rate</td><td>▁</td></tr><tr><td>batch/loss</td><td>▁</td></tr><tr><td>batch/top@5_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁</td></tr><tr><td>epoch/epoch</td><td>▁</td></tr><tr><td>epoch/learning_rate</td><td>▁</td></tr><tr><td>epoch/loss</td><td>▁</td></tr><tr><td>epoch/top@5_accuracy</td><td>▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁</td></tr><tr><td>epoch/val_loss</td><td>▁</td></tr><tr><td>epoch/val_top@5_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>top@5_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_top@5_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.24138</td></tr><tr><td>batch/accuracy</td><td>0.24138</td></tr><tr><td>batch/batch_step</td><td>0</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>5.53811</td></tr><tr><td>batch/top@5_accuracy</td><td>0.72414</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>2.37646</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>epoch/accuracy</td><td>0.24138</td></tr><tr><td>epoch/epoch</td><td>0</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>5.53811</td></tr><tr><td>epoch/top@5_accuracy</td><td>0.72414</td></tr><tr><td>epoch/val_accuracy</td><td>0.58621</td></tr><tr><td>epoch/val_loss</td><td>2.37646</td></tr><tr><td>epoch/val_top@5_accuracy</td><td>1.0</td></tr><tr><td>loss</td><td>5.53811</td></tr><tr><td>top@5_accuracy</td><td>0.72414</td></tr><tr><td>val_accuracy</td><td>0.58621</td></tr><tr><td>val_loss</td><td>2.37646</td></tr><tr><td>val_top@5_accuracy</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">model_testing_0</strong> at: <a href='https://wandb.ai/Prosody_active/Prosody/runs/k7i6h5qn' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody/runs/k7i6h5qn</a><br/> View project at: <a href='https://wandb.ai/Prosody_active/Prosody' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody</a><br/>Synced 5 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240522_012641-k7i6h5qn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k7i6h5qn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\wandb\\run-20240522_013114-nfmv2wlw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Prosody_active/Prosody/runs/nfmv2wlw' target=\"_blank\">model_testing_0</a></strong> to <a href='https://wandb.ai/Prosody_active/Prosody' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Prosody_active/Prosody' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Prosody_active/Prosody/runs/nfmv2wlw' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody/runs/nfmv2wlw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.1239 - accuracy: 0.4483 - top@5_accuracy: 0.8966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\assets\n",
      "wandb: Adding directory to artifact (.\\models)... Done. 0.3s\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\wandb\\run-20240522_013114-nfmv2wlw\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\wandb\\run-20240522_013114-nfmv2wlw\\files\\model-best\\assets\n",
      "wandb: Adding directory to artifact (c:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\wandb\\run-20240522_013114-nfmv2wlw\\files\\model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: 3.1239 - accuracy: 0.4483 - top@5_accuracy: 0.8966 - val_loss: 0.9883 - val_accuracy: 0.6897 - val_top@5_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9883 - accuracy: 0.6897 - top@5_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 556ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁██████████</td></tr><tr><td>batch/accuracy</td><td>▁</td></tr><tr><td>batch/batch_step</td><td>▁</td></tr><tr><td>batch/learning_rate</td><td>▁</td></tr><tr><td>batch/loss</td><td>▁</td></tr><tr><td>batch/top@5_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁</td></tr><tr><td>epoch/epoch</td><td>▁</td></tr><tr><td>epoch/learning_rate</td><td>▁</td></tr><tr><td>epoch/loss</td><td>▁</td></tr><tr><td>epoch/top@5_accuracy</td><td>▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁</td></tr><tr><td>epoch/val_loss</td><td>▁</td></tr><tr><td>epoch/val_top@5_accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>top@5_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_top@5_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.68966</td></tr><tr><td>batch/accuracy</td><td>0.44828</td></tr><tr><td>batch/batch_step</td><td>0</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>3.12389</td></tr><tr><td>batch/top@5_accuracy</td><td>0.89655</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.98832</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>epoch/accuracy</td><td>0.44828</td></tr><tr><td>epoch/epoch</td><td>0</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>3.12389</td></tr><tr><td>epoch/top@5_accuracy</td><td>0.89655</td></tr><tr><td>epoch/val_accuracy</td><td>0.68966</td></tr><tr><td>epoch/val_loss</td><td>0.98832</td></tr><tr><td>epoch/val_top@5_accuracy</td><td>1.0</td></tr><tr><td>loss</td><td>0.98832</td></tr><tr><td>test_accuracy</td><td>0.68966</td></tr><tr><td>test_loss</td><td>0.98832</td></tr><tr><td>top@5_accuracy</td><td>0.89655</td></tr><tr><td>val_accuracy</td><td>0.68966</td></tr><tr><td>val_loss</td><td>0.98832</td></tr><tr><td>val_top@5_accuracy</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">model_testing_0</strong> at: <a href='https://wandb.ai/Prosody_active/Prosody/runs/nfmv2wlw' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody/runs/nfmv2wlw</a><br/> View project at: <a href='https://wandb.ai/Prosody_active/Prosody' target=\"_blank\">https://wandb.ai/Prosody_active/Prosody</a><br/>Synced 5 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240522_013114-nfmv2wlw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint,  WandbCallback\n",
    "\n",
    "df = pd.read_csv(r'./Models/df_Database.csv')\n",
    "\n",
    "X= df.iloc[: ,:-1]\n",
    "y = df['Emotions']\n",
    "X = prosody_scaler.transform(X)\n",
    "y = prosody_encoder.transform(y.to_numpy().reshape(-1, 1)).toarray()  # no fit_transform as it will remove the previous state and will only have as many classes as in the current dataset\n",
    "X_cnn = np.expand_dims(X, axis=2)\n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['Emotions']\n",
    "y = prosody_encoder.transform(np.array(y).reshape(-1, 1)).toarray()\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "\n",
    "# wandb.init(project=\"Prosody\", name=\"model_testing\")\n",
    "\n",
    "#wandb.init(config={\"bs\": 12})\n",
    "\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "configs = dict(\n",
    "    num_classes =8,\n",
    "    shuffle_buffer = 1024,\n",
    "    batch_size = 32,\n",
    "    image_channels = 1,\n",
    "    earlystopping_patience = 3,\n",
    "    learning_rate = 1e-6,\n",
    "    epochs = 10\n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Add WandbCallback \n",
    "prosody_model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top@5_accuracy')]\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project = \"Prosody\",\n",
    "    name=\"model_testing_0\",\n",
    "    config = configs\n",
    ")\n",
    "    \n",
    "    \n",
    "prosody_model.fit(X, y,  validation_data=(X, y),\n",
    "          callbacks=[WandbMetricsLogger(log_freq=10),\n",
    "                     WandbModelCheckpoint(\"models\"),\n",
    "                     WandbCallback()])\n",
    "\n",
    "evaluation_results = prosody_model.evaluate(X, y)\n",
    "loss = evaluation_results[0]\n",
    "accuracy = evaluation_results[1]\n",
    "\n",
    "wandb.log({\"test_loss\": loss, \"test_accuracy\": accuracy})\n",
    "\n",
    "predictions = prosody_model.predict(X)\n",
    "\n",
    "for i in range (10):\n",
    "    wandb.log({\"loss\": loss,\n",
    "               \"accuracy\" : accuracy \n",
    "               \n",
    "               })\n",
    "\n",
    "\n",
    "\n",
    "# For instance, log a few predictions\n",
    "for i in range(10):  # Change 5 to however many predictions you want to log\n",
    "    wandb.log({\n",
    "        \"input\": X[i].tolist(),\n",
    "        \"prediction\": predictions[i].tolist(),\n",
    "        \"ground_truth\": y[i].tolist()\n",
    "    })\n",
    "\n",
    "run.finish()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X= df.iloc[: ,:-1]\n",
    "# y = df['Emotions']\n",
    "# X = prosody_scaler.transform(X)\n",
    "# y = prosody_encoder.transform(y.to_numpy().reshape(-1, 1)).toarray()  # no fit_transform as it will remove the previous state and will only have as many classes as in the current dataset\n",
    "# X_cnn = np.expand_dims(X, axis=2)\n",
    "\n",
    "\n",
    "# X = df.iloc[:, :-1]\n",
    "# y = df['Emotions']\n",
    "# y = prosody_encoder.transform(np.array(y).reshape(-1, 1)).toarray()\n",
    "# X_cnn = np.expand_dims(X, axis=2)\n",
    "# prosody_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint('./Models/Prosody_Active_Model_weights.h5', monitor='val_accuracy', save_best_only=True)\n",
    "# early_stop = EarlyStopping(monitor='val_accuracy', mode='auto', patience=3, restore_best_weights=True)\n",
    "# lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.0000001)\n",
    "\n",
    "# # Fine-tune the model\n",
    "# history = prosody_model.fit(\n",
    "#     X_cnn,\n",
    "#     y,\n",
    "#     #validation_data=(X_val, y_val),\n",
    "#     epochs=10,  \n",
    "#     batch_size=32,  \n",
    "#     callbacks=[model_checkpoint, early_stop, lr_reduction]\n",
    "# )\n",
    "\n",
    "# ########################\n",
    "# # Save fine-tuned model\n",
    "# ########################\n",
    "# prosody_model.save(r'./Models/Prosody_Active_Model.keras')\n",
    "# print('prosody active model saved')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Functions section #\n",
    "#####################################\n",
    "# geting the features from the voice\n",
    "#####################################\n",
    "\n",
    "## ZCR: Zero Crossing Rate: The rate of sign changes of the signal during the duration of a particular frame\n",
    "def zcr(data, frame_length, hop_length):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "## RMS: root mean square value\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "## MFCC: Mel Frequency Cepstral Coefficients form a cepstral representation where the frequency bands are not linear but distributed according to the mel-scale\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "## Extraxing the features\n",
    "def extract_features(data, sr=22050, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                        ))\n",
    "    return result\n",
    "\n",
    "###############################\n",
    "# features extraxtion function\n",
    "###############################\n",
    "def get_features(path):\n",
    "    \n",
    "    data, sr= librosa.load(path, duration=2.5, offset=0) # Extract for 2.5 seconds\n",
    "    \n",
    "    result=extract_features(data)\n",
    "    result=np.array(result)\n",
    "    result = np.reshape(result, (1, -1))\n",
    "    result = prosody_scaler.transform(result)  # Scaler\n",
    "    \n",
    "    return result\n",
    "\n",
    "######################\n",
    "# Prediction function\n",
    "######################\n",
    "def prediction(path):\n",
    "    result = get_features(path)\n",
    "    prediction = prosody_model.predict(result)\n",
    "    y_prediction = prosody_encoder.inverse_transform(prediction.reshape(1, -1))\n",
    "    predicted_class = y_prediction[0][0]\n",
    "    # class probabilities\n",
    "    predicted_probs = prediction[0]\n",
    "    # class names from encoder\n",
    "    class_names = prosody_encoder.categories_[0]\n",
    "    ''''\n",
    "    # Print predicted class and probabilities for all classes\n",
    "    print(\"Predictions for all classes:\")\n",
    "    for label, prob in zip(class_names, predicted_probs):\n",
    "        print(f\"{label}: {prob*100:.2f}%\")\n",
    "    '''\n",
    "    return predicted_class, predicted_probs\n",
    "\n",
    "\n",
    "###################\n",
    "# Database Function\n",
    "###################\n",
    "def df_database_function(database_folder):\n",
    "    \n",
    "    datagrams = []\n",
    "    for filename in os.listdir(database_folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            emotion = filename.split('_')[0]\n",
    "            file_path = os.path.join(database_folder, filename)\n",
    "            datagram = {'path': file_path, 'Emotions': emotion}\n",
    "            datagrams.append(datagram)\n",
    "            \n",
    "    df0 = pd.DataFrame(datagrams)\n",
    "\n",
    "    ##########################\n",
    "    # Extraction process\n",
    "    ###########################\n",
    "    def extraction_process(path, emotion):\n",
    "        features = get_features(path)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for ele in features:\n",
    "            X.append(ele)\n",
    "            Y.append(emotion)\n",
    "        return X, Y\n",
    "    \n",
    "    paths = df0.path\n",
    "    emotions = df0.Emotions\n",
    "    ##########################%%%%%% this parallel loop is chaotic in a sensse that things no longer remian in a particular order as in the df0!################################\n",
    "    # parallel loop \n",
    "    results = Parallel(n_jobs=-1)(delayed(extraction_process)(path, emotion) for (path, emotion) in zip(paths, emotions))\n",
    "    X = []\n",
    "    Y = []\n",
    "    for result in results:\n",
    "        x, y = result\n",
    "        X.extend(x)\n",
    "        Y.extend(y)\n",
    "    df = pd.DataFrame(X)\n",
    "    df['Emotions'] = Y\n",
    "    \n",
    "    return df\n",
    "\n",
    "############################\n",
    "# Model Fine-Tune \n",
    "############################\n",
    "\n",
    "def get_date_string():\n",
    "    current_datetime = datetime.now(timezone.utc)\n",
    "\n",
    "    # Format the datetime as desired\n",
    "    formatted_datetime = current_datetime.strftime('%Y_%m_%d_%H-%M')\n",
    "    return formatted_datetime\n",
    "\n",
    "def get_latest_experiment(experiments_dir = r\"tmp\"):\n",
    "\n",
    "    # List all folders in the experiments directory\n",
    "    experiment_folders = [folder for folder in os.listdir(experiments_dir)]\n",
    "    if not experiment_folders: #check if empty\n",
    "        return \"exp_\" + get_date_string()\n",
    "    \n",
    "    # Parse folder names and extract datetime information\n",
    "    parsed_folders = []\n",
    "    for folder_name in experiment_folders:\n",
    "        try:\n",
    "            folder_datetime = datetime.strptime(folder_name, 'exp_%Y_%m_%d_%H-%M')\n",
    "            parsed_folders.append((folder_datetime, folder_name))\n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "            # Skip folders with names not matching the expected format\n",
    "            pass\n",
    "\n",
    "    # Sort the parsed folders based on datetime\n",
    "    sorted_folders = sorted(parsed_folders, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Retrieve the latest folder name\n",
    "    latest_folder = sorted_folders[0][1] if sorted_folders else None\n",
    "\n",
    "    print(\"Latest experiment folder:\", latest_folder)\n",
    "\n",
    "    return latest_folder\n",
    "\n",
    "new_experiment = True\n",
    "\n",
    "def model_finetune(df):\n",
    "    X= df.iloc[: ,:-1]\n",
    "    y = df['Emotions']\n",
    "    X = prosody_scaler.transform(X)\n",
    "    y = prosody_encoder.transform(y.to_numpy().reshape(-1, 1)).toarray()  # no fit_transform as it will remove the previous state and will only have as many classes as in the current dataset\n",
    "    X_cnn = np.expand_dims(X, axis=2)\n",
    "    \n",
    "    if new_experiment: \n",
    "        exp_dir = f\"tmp/exp_{get_date_string()}\"\n",
    "    else: \n",
    "        exp_dir = get_latest_experiment(experiments_dir=r\"tmp\")\n",
    "        \n",
    "    # checkpoint_path = os.path.join(exp_dir, r\"ckpts/Model_{epoch:02d}-{accuracy:.2f}-{loss:.4f}.keras\")\n",
    "    checkpoint_path = exp_dir + r\"/ckpts/Model_{epoch:02d}-{accuracy:.2f}-{loss:.4f}.keras\"\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='loss', save_best_only=True, save_weights_only=False)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='loss', mode='auto', patience=5, restore_best_weights=True)\n",
    "\n",
    "    lr_reduction = ReduceLROnPlateau(monitor='accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.000001)\n",
    "    optimiser = Adam(learning_rate= 1e-3)\n",
    "    prosody_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = prosody_model.fit(X_cnn, y, epochs=50, batch_size=64, callbacks=[early_stop, lr_reduction, model_checkpoint])\n",
    "    history_path = exp_dir + '/history.pkl'\n",
    "    ###save the history\n",
    "    with open(history_path, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "        \n",
    "    ########################\n",
    "    # Save fine-tuned model\n",
    "    ########################\n",
    "    prosody_model.save(r'./Models/Prosody_Active_Model.keras')\n",
    "    print('prosody active model saved')\n",
    "    \n",
    "\n",
    "# database_folder = r\"./new_recordings\"\n",
    "# df_new = df_database_function(database_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 style=\"text-align: left; font-size: 28px; color: #2ecc71; font-weight: bold;\">Prosody Real-time & Prosody Active</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Prosody Real-Time & Prosody Active\n",
    "####################################\n",
    "# Ubdate prosody active Model\n",
    "###############################\n",
    "if os.path.exists(r'./Models/Prosody_Active_Model.keras'):\n",
    "    prosody_model = tf.keras.models.load_model(r'./Models/Prosody_Active_Model.keras')\n",
    "    print (\"Prosody active model has been loaded\")\n",
    "######################################################################################    \n",
    "\n",
    "class EmotionPlotter:\n",
    "    def __init__(self, root, update_callback):\n",
    "        self.root = root\n",
    "        self.root.lift()\n",
    "        self.root.title(\"Emotion Prediction\")\n",
    "        \n",
    "        frame_color= '#F5F5F5'\n",
    "        #self.root.configure(bg='#2c3e50')\n",
    "        self.root.configure(bg=frame_color)\n",
    "        self.update_callback = update_callback\n",
    "        self.class_names = ['Noise', 'angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 4.5))  # Set the facecolor to dark mode\n",
    "        self.ax.set_title('Emotion Prediction')\n",
    "        self.ax.set_xlabel('Emotion')\n",
    "        self.ax.set_ylabel('Probability (%)')\n",
    "        self.ax.set_ylim(0, 100)\n",
    "        self.ax.set_xticks(np.arange(len(self.class_names)))\n",
    "        self.ax.set_xticklabels(self.class_names, rotation=0)\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.root)\n",
    "        self.canvas.draw()\n",
    "        self.canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "        #########################\n",
    "        # Recording configuration\n",
    "        #########################\n",
    "        self.RECORD_SECONDS = 2.5  # recording duration\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 44100\n",
    "        self.CHUNK = 1024\n",
    "        self.CHUNK_SIZE = 1024\n",
    "        self.OUTPUT_FILE = OUTPUT_FILE\n",
    "        #######################################################################\n",
    "        #########################\n",
    "        # buttons configuration\n",
    "        ##########################\n",
    "        # Button styles\n",
    "        button_font = ('Helvetica', 14, 'bold')\n",
    "        button_style = {\n",
    "            'font': button_font,\n",
    "            'bg': '#2c3e60',  # Green background\n",
    "            'fg': 'white',    # White text\n",
    "            'activebackground': '#2c3e55',  # Darker green when pressed\n",
    "            'activeforeground': 'white',    # White text when pressed\n",
    "            'borderwidth': 0,\n",
    "            'padx': 10,\n",
    "            'pady': 5\n",
    "        }\n",
    "\n",
    "        # Create a frame for the buttons\n",
    "        button_frame = tk.Frame(self.root, bg=frame_color)\n",
    "        button_frame.pack(side=tk.TOP, pady=(10, 10))\n",
    "\n",
    "        # Start button\n",
    "        self.start_button = tk.Button(\n",
    "            button_frame, text=\"Start Recording\",\n",
    "            command=self.start_visualization,\n",
    "            **button_style\n",
    "        )\n",
    "        self.start_button.pack(side=tk.LEFT, padx=10, pady=5)\n",
    "\n",
    "        # Continue button\n",
    "        self.continue_button = tk.Button(\n",
    "            button_frame, text=\"Active Mode\",\n",
    "            command=self.active_mode,\n",
    "            **button_style\n",
    "        )\n",
    "        self.continue_button.pack(side=tk.LEFT, padx=10, pady=5)\n",
    "        self.continue_button['state'] = tk.DISABLED\n",
    "\n",
    "        # Exit button\n",
    "        self.exit_button = tk.Button(\n",
    "            button_frame, text=\"Exit\",\n",
    "            command=self.root.destroy,\n",
    "            **button_style\n",
    "        )\n",
    "        self.exit_button.pack(side=tk.RIGHT, padx=10, pady=5)\n",
    "        self.exit_button['state'] = tk.NORMAL\n",
    "\n",
    "        # Listen button\n",
    "        self.listen_button = tk.Button(\n",
    "            button_frame, text=\"Play the Voice\",\n",
    "            command=self.play_voice,\n",
    "            **button_style\n",
    "        )\n",
    "        self.listen_button.pack(side=tk.RIGHT, padx=10, pady=5)\n",
    "        self.listen_button['state'] = tk.DISABLED\n",
    "        self.visualizing = False                 # track of visualization state\n",
    "        self.root.after(0, self.center_window)  \n",
    "        \n",
    "    def center_window(self):\n",
    "        self.root.update_idletasks()  \n",
    "        width = self.root.winfo_width()\n",
    "        height = self.root.winfo_height()\n",
    "        x = (self.root.winfo_screenwidth() // 2) - (width // 2)\n",
    "        y = (self.root.winfo_screenheight() // 2) - (height // 2)\n",
    "        self.root.geometry(f'{width}x{height}+{x}+{y}')\n",
    "\n",
    "    ############################################################\n",
    "    ############################        \n",
    "    # buttons update\n",
    "    ##########################\n",
    "    def start_visualization(self):\n",
    "        if not self.visualizing:\n",
    "            self.visualizing = True\n",
    "            self.start_button['state'] = tk.DISABLED\n",
    "            self.continue_button['state'] = tk.DISABLED\n",
    "            self.listen_button['state'] = tk.DISABLED\n",
    "            self.update_start_loop()\n",
    "    \n",
    "    def active_mode(self):\n",
    "        if not self.visualizing:\n",
    "            self.visualizing = True\n",
    "            self.start_button['state'] = tk.DISABLED\n",
    "            self.continue_button['state'] = tk.DISABLED\n",
    "            self.listen_button['state'] = tk.DISABLED\n",
    "            self.exit_button['state'] = tk.DISABLED\n",
    "            self.visualizing = False       \n",
    "        #OUTPUT_FILE=r\"./Output/input_voice.wav\"\n",
    "        database_folder= r'./Database'\n",
    "        self.Prosody_active(self.OUTPUT_FILE, database_folder, self.start_button, self.continue_button, self.listen_button, self.exit_button).active_GUI()\n",
    "          \n",
    "    def play_voice(self):\n",
    "        playsound(OUTPUT_FILE)\n",
    "        \n",
    "    def update_start_text(self, text):\n",
    "        self.start_button.config(text=text)\n",
    "        self.root.update()\n",
    "        \n",
    "    def update_continue_text(self, text):\n",
    "        self.continue_button.config(text=text)\n",
    "        self.root.update()   \n",
    "             \n",
    "    def update_start_loop(self):\n",
    "        ########################\n",
    "        # Start recording audio\n",
    "        ########################\n",
    "        self.update_start_text(\"Recording in Progress...\")\n",
    "        print(\"Listening...\")\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RATE, input=True, frames_per_buffer=self.CHUNK)\n",
    "        frames = []\n",
    "        # Recording \n",
    "        for i in range(0, int(self.RATE / self.CHUNK_SIZE * self.RECORD_SECONDS)):\n",
    "            data = stream.read(self.CHUNK_SIZE)\n",
    "            frames.append(data)\n",
    "        # Stop recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        # Saving audio\n",
    "        with wave.open(self.OUTPUT_FILE, 'wb') as wf:\n",
    "            wf.setnchannels(self.CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(self.FORMAT))\n",
    "            wf.setframerate(self.RATE)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "             \n",
    "        ######################\n",
    "        # Perform prediction\n",
    "        ######################\n",
    "        self.update_start_text(\"Restart Recording\")\n",
    "        #self.update_continue(\"active Model\")\n",
    "        self.start_button['state'] = tk.NORMAL\n",
    "        self.continue_button['state'] = tk.NORMAL\n",
    "        self.listen_button['state'] = tk.NORMAL\n",
    "        #######################\n",
    "        global PREDICTED_CLASS\n",
    "        #######################\n",
    "        PREDICTED_CLASS, predicted_probs = prediction(self.OUTPUT_FILE)\n",
    "        # callback\n",
    "        self.update_callback(self, PREDICTED_CLASS, predicted_probs)\n",
    "        # Reset visualization\n",
    "        self.visualizing = False\n",
    "        self.root.update() \n",
    "    ##################################################################\n",
    "    ########################\n",
    "    # Update Plot\n",
    "    ########################\n",
    "    def update_plot(self, predicted_probs):\n",
    "        self.ax.clear()\n",
    "        bars = self.ax.bar(self.class_names, predicted_probs * 100, color='blue')\n",
    "        self.ax.set_title('Emotion Prediction')\n",
    "        self.ax.set_xlabel('Emotion')\n",
    "        self.ax.set_ylabel('Probability (%)')\n",
    "        self.ax.set_ylim(0, 100)\n",
    "        self.ax.set_xticks(np.arange(len(self.class_names)))\n",
    "        self.ax.set_xticklabels(self.class_names, rotation=0)\n",
    "        for i, bar in enumerate(bars):\n",
    "            self.ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{predicted_probs[i]*100:.2f}%', ha='center', va='bottom')\n",
    "        self.canvas.draw()\n",
    "   \n",
    "   \n",
    "    #######################################################################################\n",
    "    #######################################################################################\n",
    "    # active-learning      \n",
    "    #######################################################################################\n",
    "    #######################################################################################\n",
    "    class Prosody_active:\n",
    "        def __init__ (self, output_file, output_folder, start_button, continue_button, listen_button,exit_button):\n",
    "            self.start_button = start_button\n",
    "            self.continue_button = continue_button\n",
    "            self.listen_button = listen_button\n",
    "            self.exit_button = exit_button\n",
    "            \n",
    "            self.OUTPUT_FILE = output_file\n",
    "            self.database_folder = output_folder\n",
    "            self.predicted_class = PREDICTED_CLASS\n",
    "            self.classes = ['Noise', 'angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "            self.selected_label = tk.StringVar()\n",
    "            self.root = tk.Toplevel()               # giving active Gui Root other level as main Gui Root\n",
    "            self.root.title(\"Prosody Active-Learning\")\n",
    "            self.root.geometry(\"700x200\")\n",
    "            self.selected_label.set(None)\n",
    "            self.root.protocol(\"WM_DELETE_WINDOW\", self.on_window_close)\n",
    "            self.root.after(0, self.center_window)\n",
    "            \n",
    "        def center_window(self):\n",
    "            self.root.update_idletasks()  \n",
    "            width = self.root.winfo_width()\n",
    "            height = self.root.winfo_height()\n",
    "            x = (self.root.winfo_screenwidth() // 2) - (width // 2)\n",
    "            y = (self.root.winfo_screenheight() // 2) - (height // 2)\n",
    "            self.root.geometry(f'{width}x{height}+{x}+{y}')\n",
    "\n",
    "        def on_window_close(self):\n",
    "                # Reset button states when window is closed\n",
    "                self.start_button['state'] = tk.NORMAL\n",
    "                self.continue_button['state'] = tk.NORMAL\n",
    "                self.listen_button['state'] = tk.NORMAL\n",
    "                self.exit_button['state'] = tk.NORMAL\n",
    "                # Destroy the window\n",
    "                self.root.destroy()\n",
    "        #######################\n",
    "        # Data Folder structure\n",
    "        #######################       \n",
    "        def save_data(self, selected_value):    \n",
    "            if not os.path.exists(self.database_folder):\n",
    "                os.makedirs(self.database_folder)\n",
    "                \n",
    "            existing_files = [f for f in os.listdir(self.database_folder) if f.endswith('.wav')]\n",
    "            ##########################\n",
    "            # Find the max file value\n",
    "            ##########################\n",
    "            max_number = 0\n",
    "            for file_name in existing_files:\n",
    "                match = re.match(rf\"{selected_value}_(\\d+)\\.wav\", file_name)\n",
    "                if match:\n",
    "                    number = int(match.group(1))\n",
    "                    max_number = max(max_number, number)\n",
    "            ###########################   \n",
    "            # save the file\n",
    "            ###############\n",
    "            new_file_name = f\"{selected_value}_{max_number + 1}.wav\"\n",
    "            output_file_path = os.path.join(self.database_folder, new_file_name)\n",
    "            shutil.copyfile(self.OUTPUT_FILE, output_file_path)\n",
    "            print('saved to Database')\n",
    "            ############################\n",
    "            messagebox.showinfo(\"Success\", \"Information saved to Prosody Database.\")\n",
    "        #####################################################################################\n",
    "        ############################\n",
    "        # Fine Tune\n",
    "        #############################\n",
    "        def fine_tune(self, correct_label):\n",
    "        \n",
    "            print ('correct_label: ', correct_label)\n",
    "            \n",
    "            df_database = pd.DataFrame()\n",
    "            df_database = df_database_function(self.database_folder)\n",
    "            df_database.to_csv(r'./Models/df_Database.csv', index = False)\n",
    "            model_finetune(df_database)\n",
    "\n",
    "            messagebox.showinfo(\"Success\", \"Model retrained with the new information.\")\n",
    "            self.root.destroy()\n",
    "        #################################################################################            \n",
    "        ###########################\n",
    "        # Save without training\n",
    "        ###########################\n",
    "        def B_save_data(self):\n",
    "            selected_value = self.selected_label.get()\n",
    "            if selected_value in self.classes:\n",
    "                self.save_data(selected_value)\n",
    "                print('Data saved without training. Selected label: ', selected_value)\n",
    "\n",
    "                self.start_button['state'] = tk.NORMAL\n",
    "                self.continue_button['state'] = tk.NORMAL\n",
    "                self.listen_button['state'] = tk.NORMAL\n",
    "                self.exit_button['state'] = tk.NORMAL\n",
    "                self.visualizing = False\n",
    "                self.root.update()\n",
    "                \n",
    "                if tk._default_root is not None:  # check root window exists\n",
    "                    self.root.destroy()\n",
    "        #########################################################################            \n",
    "        ############################# \n",
    "        # Save and Retrain the model\n",
    "        #############################\n",
    "        def B_save_retrain(self):\n",
    "            self.start_button.config(text='Retraining')\n",
    "            self.continue_button.config(text='in')\n",
    "            self.listen_button.config(text='progress')\n",
    "            self.exit_button.config(text='...')\n",
    "            \n",
    "            selected_value = self.selected_label.get()\n",
    "            if selected_value in self.classes:\n",
    "                self.save_data(selected_value)\n",
    "                self.fine_tune(selected_value)\n",
    "                print('Selected label: ', selected_value)\n",
    "                \n",
    "                self.start_button['state'] = tk.NORMAL\n",
    "                self.continue_button['state'] = tk.NORMAL\n",
    "                self.listen_button['state'] = tk.NORMAL\n",
    "                self.exit_button['state'] = tk.NORMAL\n",
    "                \n",
    "                self.start_button.config(text='Restart Recording')\n",
    "                self.continue_button.config(text='Active Mode')\n",
    "                self.listen_button.config(text='Play the Voice')\n",
    "                self.exit_button.config(text='Exit')\n",
    "                \n",
    "                self.visualizing = False\n",
    "                self.root.update()\n",
    "                \n",
    "                if tk._default_root is not None:  # check root window exists\n",
    "                    self.root.destroy()\n",
    "        ########################################################################            \n",
    "        ###########################\n",
    "        # Bottums & Perform text \n",
    "        ###########################\n",
    "        def active_GUI(self):\n",
    "            #self.selected_label.set(None)\n",
    "            predicted_label_text = tk.StringVar()\n",
    "            predicted_label_text.set(\"Predicted Class: \" + self.predicted_class + \"\\n Correct the Class\")\n",
    "            predicted_label_label = tk.Label(self.root, textvariable=predicted_label_text, font=(\"Arial\", 16))\n",
    "            predicted_label_label.pack()\n",
    "            checkbox_frame = tk.Frame(self.root)\n",
    "            checkbox_frame.pack(padx=10, pady=10)\n",
    "            for label in self.classes:\n",
    "                radio_button = Radiobutton(checkbox_frame, text=label, variable=self.selected_label, value=label,\n",
    "                                        font=(\"Arial\", 14))\n",
    "                radio_button.pack(side=tk.LEFT, padx=10)\n",
    "            save_button = tk.Button(self.root, text=\"Save to Database\", command=self.B_save_data, font=(\"Arial\", 14))\n",
    "            save_button.pack()\n",
    "\n",
    "            save_retrain_button = tk.Button(self.root, text=\"Save to Database and retrain the model\",\n",
    "                                            command=self.B_save_retrain, font=(\"Arial\", 14))\n",
    "            save_retrain_button.pack()\n",
    "\n",
    "            self.root.mainloop()\n",
    "            \n",
    "            \n",
    "def visualize_emotion_prediction(plotter, predicted_class, predicted_probs):\n",
    "    plotter.update_plot(predicted_probs)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # callback function\n",
    "#     root = tk.Tk() #root window\n",
    "#     ####################################\n",
    "#     # Ensure the window stays on top initially\n",
    "#     root.attributes(\"-topmost\", True)\n",
    "#     root.after(0, lambda: root.attributes(\"-topmost\", False))\n",
    "#     root.lift()\n",
    "#     #####################################\n",
    "#     plotter = EmotionPlotter(root, visualize_emotion_prediction)\n",
    "#     root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "Listening...\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Listening...\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "saved to Database\n",
      "correct_label:  happy\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.5657 - accuracy: 0.1379 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 3.2137 - accuracy: 0.4828 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 1.3089 - accuracy: 0.7586 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 1.0105 - accuracy: 0.6552 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6742 - accuracy: 0.7931 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.1613 - accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.1858 - accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.1145 - accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0782 - accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0558 - accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9655\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.0766 - accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0546 - accuracy: 0.9655 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0382 - accuracy: 0.9655 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 9.0374e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 0.0064 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.0036 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 0.0337 - accuracy: 0.9655 - lr: 2.5000e-04\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "prosody active model saved\n",
      "Selected label:  happy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################\n",
    "# Welcome Gui\n",
    "################\n",
    "\n",
    "class welcome_GUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        self.setup_master()\n",
    "        self.setup_styles()\n",
    "        self.create_widgets()\n",
    "        self.master.after(0, self.center_window)  # Schedule centering after the window is fully initialized\n",
    "\n",
    "    def setup_master(self):\n",
    "        self.master.title(\"Prosody Active Emotion\")\n",
    "        self.master.geometry(\"280x120\")\n",
    "\n",
    "    def setup_styles(self):\n",
    "        self.style = ttk.Style()\n",
    "        self.style.configure('TLabel', font=('Arial', 12, 'bold'))\n",
    "        self.style.configure('TButton', font=('Arial', 12, 'bold'))\n",
    "        self.style.configure('TEntry', font=('Arial', 12, 'bold'))\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        # Header\n",
    "        header_label = ttk.Label(self.master, text=\"Prosody Active Emotion\", style='TLabel')\n",
    "        header_label.pack(pady=(10, 20))\n",
    "\n",
    "        # Start button \n",
    "        self.start_button = ttk.Button(self.master, text=\"Start\", command=self.start_recording, style='TButton')\n",
    "        self.start_button.pack(pady=(0, 10))\n",
    "\n",
    "        # Status label\n",
    "        self.status_label = ttk.Label(self.master, text=\"\", style='TLabel')\n",
    "        self.status_label.pack(pady=10)\n",
    "\n",
    "    def center_window(self):\n",
    "        self.master.update_idletasks()  # Ensure geometry information is updated\n",
    "        width = self.master.winfo_width()\n",
    "        height = self.master.winfo_height()\n",
    "        x = (self.master.winfo_screenwidth() // 2) - (width // 2)\n",
    "        y = (self.master.winfo_screenheight() // 2) - (height // 2)\n",
    "        self.master.geometry(f'{width}x{height}+{x}+{y}')\n",
    "    ######################\n",
    "    # Recording Voice ID\n",
    "    ######################\n",
    "    def start_recording(self):\n",
    "        if __name__ == \"__main__\":\n",
    "            self.master.destroy()\n",
    "            \n",
    "            # callback function\n",
    "            root = tk.Tk() #root window\n",
    "            ####################################\n",
    "            # Ensure the window stays on top initially\n",
    "            root.attributes(\"-topmost\", True)\n",
    "            root.after(0, lambda: root.attributes(\"-topmost\", False))\n",
    "            root.lift()\n",
    "            #####################################\n",
    "            plotter = EmotionPlotter(root, visualize_emotion_prediction)\n",
    "            root.mainloop()\n",
    "\n",
    "                 \n",
    "root = tk.Tk()\n",
    "# Ensure the window stays on top initially\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.after(0, lambda: root.attributes(\"-topmost\", False))\n",
    "root.lift()\n",
    "app = welcome_GUI(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.555663</td>\n",
       "      <td>-0.996810</td>\n",
       "      <td>-1.033808</td>\n",
       "      <td>0.441149</td>\n",
       "      <td>-0.924505</td>\n",
       "      <td>0.232787</td>\n",
       "      <td>0.871313</td>\n",
       "      <td>-0.268860</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.555663</td>\n",
       "      <td>-0.996810</td>\n",
       "      <td>-1.033808</td>\n",
       "      <td>0.441149</td>\n",
       "      <td>-0.924505</td>\n",
       "      <td>0.232787</td>\n",
       "      <td>0.871313</td>\n",
       "      <td>-0.268860</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.555663</td>\n",
       "      <td>-0.996810</td>\n",
       "      <td>-1.033808</td>\n",
       "      <td>0.441149</td>\n",
       "      <td>-0.924505</td>\n",
       "      <td>0.232787</td>\n",
       "      <td>0.871313</td>\n",
       "      <td>-0.268860</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.555663</td>\n",
       "      <td>-0.996810</td>\n",
       "      <td>-1.033808</td>\n",
       "      <td>0.441149</td>\n",
       "      <td>-0.924505</td>\n",
       "      <td>0.232787</td>\n",
       "      <td>0.871313</td>\n",
       "      <td>-0.268860</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580477</td>\n",
       "      <td>-0.644837</td>\n",
       "      <td>-0.736627</td>\n",
       "      <td>-0.840287</td>\n",
       "      <td>-0.918935</td>\n",
       "      <td>-0.983371</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-0.869366</td>\n",
       "      <td>-0.712019</td>\n",
       "      <td>-0.604034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644083</td>\n",
       "      <td>0.616531</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.412014</td>\n",
       "      <td>1.838805</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>1.395948</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.155367</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.580477</td>\n",
       "      <td>-0.644837</td>\n",
       "      <td>-0.736627</td>\n",
       "      <td>-0.840287</td>\n",
       "      <td>-0.918935</td>\n",
       "      <td>-0.983371</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-0.869366</td>\n",
       "      <td>-0.712019</td>\n",
       "      <td>-0.604034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644083</td>\n",
       "      <td>0.616531</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.412014</td>\n",
       "      <td>1.838805</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>1.395948</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.155367</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.580477</td>\n",
       "      <td>-0.644837</td>\n",
       "      <td>-0.736627</td>\n",
       "      <td>-0.840287</td>\n",
       "      <td>-0.918935</td>\n",
       "      <td>-0.983371</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-0.869366</td>\n",
       "      <td>-0.712019</td>\n",
       "      <td>-0.604034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644083</td>\n",
       "      <td>0.616531</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.412014</td>\n",
       "      <td>1.838805</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>1.395948</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.155367</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.580477</td>\n",
       "      <td>-0.644837</td>\n",
       "      <td>-0.736627</td>\n",
       "      <td>-0.840287</td>\n",
       "      <td>-0.918935</td>\n",
       "      <td>-0.983371</td>\n",
       "      <td>-0.985342</td>\n",
       "      <td>-0.869366</td>\n",
       "      <td>-0.712019</td>\n",
       "      <td>-0.604034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.644083</td>\n",
       "      <td>0.616531</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.412014</td>\n",
       "      <td>1.838805</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>1.395948</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.155367</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.108173</td>\n",
       "      <td>1.999796</td>\n",
       "      <td>1.934228</td>\n",
       "      <td>1.761484</td>\n",
       "      <td>1.665541</td>\n",
       "      <td>1.615386</td>\n",
       "      <td>1.598249</td>\n",
       "      <td>1.615776</td>\n",
       "      <td>1.673500</td>\n",
       "      <td>1.776872</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.529741</td>\n",
       "      <td>2.184693</td>\n",
       "      <td>-0.401723</td>\n",
       "      <td>1.443071</td>\n",
       "      <td>-0.171990</td>\n",
       "      <td>1.607917</td>\n",
       "      <td>0.942241</td>\n",
       "      <td>-0.708967</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-0.903108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015361</td>\n",
       "      <td>-0.278931</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>-0.200957</td>\n",
       "      <td>0.580537</td>\n",
       "      <td>1.258397</td>\n",
       "      <td>1.776845</td>\n",
       "      <td>0.134927</td>\n",
       "      <td>1.858365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-0.903108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015361</td>\n",
       "      <td>-0.278931</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>-0.200957</td>\n",
       "      <td>0.580537</td>\n",
       "      <td>1.258397</td>\n",
       "      <td>1.776845</td>\n",
       "      <td>0.134927</td>\n",
       "      <td>1.858365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-0.903108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015361</td>\n",
       "      <td>-0.278931</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>-0.200957</td>\n",
       "      <td>0.580537</td>\n",
       "      <td>1.258397</td>\n",
       "      <td>1.776845</td>\n",
       "      <td>0.134927</td>\n",
       "      <td>1.858365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-0.903108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015361</td>\n",
       "      <td>-0.278931</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>-0.200957</td>\n",
       "      <td>0.580537</td>\n",
       "      <td>1.258397</td>\n",
       "      <td>1.776845</td>\n",
       "      <td>0.134927</td>\n",
       "      <td>1.858365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.179472</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>-0.074923</td>\n",
       "      <td>-0.150759</td>\n",
       "      <td>-0.193208</td>\n",
       "      <td>-0.326908</td>\n",
       "      <td>-0.496155</td>\n",
       "      <td>-0.581859</td>\n",
       "      <td>-0.622726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230919</td>\n",
       "      <td>0.967209</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>-1.099283</td>\n",
       "      <td>0.436404</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.961930</td>\n",
       "      <td>-0.629323</td>\n",
       "      <td>2.220373</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.179472</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>-0.074923</td>\n",
       "      <td>-0.150759</td>\n",
       "      <td>-0.193208</td>\n",
       "      <td>-0.326908</td>\n",
       "      <td>-0.496155</td>\n",
       "      <td>-0.581859</td>\n",
       "      <td>-0.622726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230919</td>\n",
       "      <td>0.967209</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>-1.099283</td>\n",
       "      <td>0.436404</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.961930</td>\n",
       "      <td>-0.629323</td>\n",
       "      <td>2.220373</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.179472</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>-0.074923</td>\n",
       "      <td>-0.150759</td>\n",
       "      <td>-0.193208</td>\n",
       "      <td>-0.326908</td>\n",
       "      <td>-0.496155</td>\n",
       "      <td>-0.581859</td>\n",
       "      <td>-0.622726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230919</td>\n",
       "      <td>0.967209</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>-1.099283</td>\n",
       "      <td>0.436404</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.961930</td>\n",
       "      <td>-0.629323</td>\n",
       "      <td>2.220373</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.179472</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>-0.074923</td>\n",
       "      <td>-0.150759</td>\n",
       "      <td>-0.193208</td>\n",
       "      <td>-0.326908</td>\n",
       "      <td>-0.496155</td>\n",
       "      <td>-0.581859</td>\n",
       "      <td>-0.622726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230919</td>\n",
       "      <td>0.967209</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>-1.099283</td>\n",
       "      <td>0.436404</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.961930</td>\n",
       "      <td>-0.629323</td>\n",
       "      <td>2.220373</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.973555</td>\n",
       "      <td>-0.958376</td>\n",
       "      <td>-0.941500</td>\n",
       "      <td>-0.919624</td>\n",
       "      <td>-0.869665</td>\n",
       "      <td>-0.873626</td>\n",
       "      <td>-0.867609</td>\n",
       "      <td>-0.889124</td>\n",
       "      <td>-0.925212</td>\n",
       "      <td>-0.905444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081144</td>\n",
       "      <td>0.802865</td>\n",
       "      <td>0.395751</td>\n",
       "      <td>0.160425</td>\n",
       "      <td>0.798398</td>\n",
       "      <td>0.611098</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.693781</td>\n",
       "      <td>0.961922</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.973555</td>\n",
       "      <td>-0.958376</td>\n",
       "      <td>-0.941500</td>\n",
       "      <td>-0.919624</td>\n",
       "      <td>-0.869665</td>\n",
       "      <td>-0.873626</td>\n",
       "      <td>-0.867609</td>\n",
       "      <td>-0.889124</td>\n",
       "      <td>-0.925212</td>\n",
       "      <td>-0.905444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081144</td>\n",
       "      <td>0.802865</td>\n",
       "      <td>0.395751</td>\n",
       "      <td>0.160425</td>\n",
       "      <td>0.798398</td>\n",
       "      <td>0.611098</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.693781</td>\n",
       "      <td>0.961922</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.973555</td>\n",
       "      <td>-0.958376</td>\n",
       "      <td>-0.941500</td>\n",
       "      <td>-0.919624</td>\n",
       "      <td>-0.869665</td>\n",
       "      <td>-0.873626</td>\n",
       "      <td>-0.867609</td>\n",
       "      <td>-0.889124</td>\n",
       "      <td>-0.925212</td>\n",
       "      <td>-0.905444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081144</td>\n",
       "      <td>0.802865</td>\n",
       "      <td>0.395751</td>\n",
       "      <td>0.160425</td>\n",
       "      <td>0.798398</td>\n",
       "      <td>0.611098</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.693781</td>\n",
       "      <td>0.961922</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.973555</td>\n",
       "      <td>-0.958376</td>\n",
       "      <td>-0.941500</td>\n",
       "      <td>-0.919624</td>\n",
       "      <td>-0.869665</td>\n",
       "      <td>-0.873626</td>\n",
       "      <td>-0.867609</td>\n",
       "      <td>-0.889124</td>\n",
       "      <td>-0.925212</td>\n",
       "      <td>-0.905444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081144</td>\n",
       "      <td>0.802865</td>\n",
       "      <td>0.395751</td>\n",
       "      <td>0.160425</td>\n",
       "      <td>0.798398</td>\n",
       "      <td>0.611098</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>0.693781</td>\n",
       "      <td>0.961922</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707326</td>\n",
       "      <td>1.083963</td>\n",
       "      <td>-0.731091</td>\n",
       "      <td>0.189046</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>-0.704857</td>\n",
       "      <td>1.735322</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707326</td>\n",
       "      <td>1.083963</td>\n",
       "      <td>-0.731091</td>\n",
       "      <td>0.189046</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>-0.704857</td>\n",
       "      <td>1.735322</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707326</td>\n",
       "      <td>1.083963</td>\n",
       "      <td>-0.731091</td>\n",
       "      <td>0.189046</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>-0.704857</td>\n",
       "      <td>1.735322</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707326</td>\n",
       "      <td>1.083963</td>\n",
       "      <td>-0.731091</td>\n",
       "      <td>0.189046</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>-0.704857</td>\n",
       "      <td>1.735322</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822564</td>\n",
       "      <td>1.388583</td>\n",
       "      <td>-1.446703</td>\n",
       "      <td>0.370446</td>\n",
       "      <td>1.296568</td>\n",
       "      <td>-0.441104</td>\n",
       "      <td>2.673223</td>\n",
       "      <td>-0.103134</td>\n",
       "      <td>-0.915359</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822564</td>\n",
       "      <td>1.388583</td>\n",
       "      <td>-1.446703</td>\n",
       "      <td>0.370446</td>\n",
       "      <td>1.296568</td>\n",
       "      <td>-0.441104</td>\n",
       "      <td>2.673223</td>\n",
       "      <td>-0.103134</td>\n",
       "      <td>-0.915359</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822564</td>\n",
       "      <td>1.388583</td>\n",
       "      <td>-1.446703</td>\n",
       "      <td>0.370446</td>\n",
       "      <td>1.296568</td>\n",
       "      <td>-0.441104</td>\n",
       "      <td>2.673223</td>\n",
       "      <td>-0.103134</td>\n",
       "      <td>-0.915359</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.078375</td>\n",
       "      <td>-1.081065</td>\n",
       "      <td>-1.081414</td>\n",
       "      <td>-1.054963</td>\n",
       "      <td>-1.039873</td>\n",
       "      <td>-1.036048</td>\n",
       "      <td>-1.033308</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>-1.037419</td>\n",
       "      <td>-1.045635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822564</td>\n",
       "      <td>1.388583</td>\n",
       "      <td>-1.446703</td>\n",
       "      <td>0.370446</td>\n",
       "      <td>1.296568</td>\n",
       "      <td>-0.441104</td>\n",
       "      <td>2.673223</td>\n",
       "      <td>-0.103134</td>\n",
       "      <td>-0.915359</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 2377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "1  -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "2  -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "3  -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "4  -0.580477 -0.644837 -0.736627 -0.840287 -0.918935 -0.983371 -0.985342   \n",
       "5  -0.580477 -0.644837 -0.736627 -0.840287 -0.918935 -0.983371 -0.985342   \n",
       "6  -0.580477 -0.644837 -0.736627 -0.840287 -0.918935 -0.983371 -0.985342   \n",
       "7  -0.580477 -0.644837 -0.736627 -0.840287 -0.918935 -0.983371 -0.985342   \n",
       "8   2.108173  1.999796  1.934228  1.761484  1.665541  1.615386  1.598249   \n",
       "9  -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "10 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "11 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "12 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "13  0.179472  0.019729 -0.022067 -0.074923 -0.150759 -0.193208 -0.326908   \n",
       "14  0.179472  0.019729 -0.022067 -0.074923 -0.150759 -0.193208 -0.326908   \n",
       "15  0.179472  0.019729 -0.022067 -0.074923 -0.150759 -0.193208 -0.326908   \n",
       "16  0.179472  0.019729 -0.022067 -0.074923 -0.150759 -0.193208 -0.326908   \n",
       "17 -0.973555 -0.958376 -0.941500 -0.919624 -0.869665 -0.873626 -0.867609   \n",
       "18 -0.973555 -0.958376 -0.941500 -0.919624 -0.869665 -0.873626 -0.867609   \n",
       "19 -0.973555 -0.958376 -0.941500 -0.919624 -0.869665 -0.873626 -0.867609   \n",
       "20 -0.973555 -0.958376 -0.941500 -0.919624 -0.869665 -0.873626 -0.867609   \n",
       "21 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "22 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "23 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "24 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "25 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "26 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "27 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "28 -1.078375 -1.081065 -1.081414 -1.054963 -1.039873 -1.036048 -1.033308   \n",
       "\n",
       "           7         8         9  ...      2367      2368      2369      2370  \\\n",
       "0  -1.034017 -1.037419 -1.045635  ...  0.509767  1.555663 -0.996810 -1.033808   \n",
       "1  -1.034017 -1.037419 -1.045635  ...  0.509767  1.555663 -0.996810 -1.033808   \n",
       "2  -1.034017 -1.037419 -1.045635  ...  0.509767  1.555663 -0.996810 -1.033808   \n",
       "3  -1.034017 -1.037419 -1.045635  ...  0.509767  1.555663 -0.996810 -1.033808   \n",
       "4  -0.869366 -0.712019 -0.604034  ... -0.644083  0.616531  0.216755  0.412014   \n",
       "5  -0.869366 -0.712019 -0.604034  ... -0.644083  0.616531  0.216755  0.412014   \n",
       "6  -0.869366 -0.712019 -0.604034  ... -0.644083  0.616531  0.216755  0.412014   \n",
       "7  -0.869366 -0.712019 -0.604034  ... -0.644083  0.616531  0.216755  0.412014   \n",
       "8   1.615776  1.673500  1.776872  ... -1.529741  2.184693 -0.401723  1.443071   \n",
       "9  -1.034017 -1.037419 -0.903108  ... -1.015361 -0.278931  0.505563 -0.200957   \n",
       "10 -1.034017 -1.037419 -0.903108  ... -1.015361 -0.278931  0.505563 -0.200957   \n",
       "11 -1.034017 -1.037419 -0.903108  ... -1.015361 -0.278931  0.505563 -0.200957   \n",
       "12 -1.034017 -1.037419 -0.903108  ... -1.015361 -0.278931  0.505563 -0.200957   \n",
       "13 -0.496155 -0.581859 -0.622726  ... -0.230919  0.967209  0.709352 -1.099283   \n",
       "14 -0.496155 -0.581859 -0.622726  ... -0.230919  0.967209  0.709352 -1.099283   \n",
       "15 -0.496155 -0.581859 -0.622726  ... -0.230919  0.967209  0.709352 -1.099283   \n",
       "16 -0.496155 -0.581859 -0.622726  ... -0.230919  0.967209  0.709352 -1.099283   \n",
       "17 -0.889124 -0.925212 -0.905444  ... -0.081144  0.802865  0.395751  0.160425   \n",
       "18 -0.889124 -0.925212 -0.905444  ... -0.081144  0.802865  0.395751  0.160425   \n",
       "19 -0.889124 -0.925212 -0.905444  ... -0.081144  0.802865  0.395751  0.160425   \n",
       "20 -0.889124 -0.925212 -0.905444  ... -0.081144  0.802865  0.395751  0.160425   \n",
       "21 -1.034017 -1.037419 -1.045635  ... -0.707326  1.083963 -0.731091  0.189046   \n",
       "22 -1.034017 -1.037419 -1.045635  ... -0.707326  1.083963 -0.731091  0.189046   \n",
       "23 -1.034017 -1.037419 -1.045635  ... -0.707326  1.083963 -0.731091  0.189046   \n",
       "24 -1.034017 -1.037419 -1.045635  ... -0.707326  1.083963 -0.731091  0.189046   \n",
       "25 -1.034017 -1.037419 -1.045635  ... -0.822564  1.388583 -1.446703  0.370446   \n",
       "26 -1.034017 -1.037419 -1.045635  ... -0.822564  1.388583 -1.446703  0.370446   \n",
       "27 -1.034017 -1.037419 -1.045635  ... -0.822564  1.388583 -1.446703  0.370446   \n",
       "28 -1.034017 -1.037419 -1.045635  ... -0.822564  1.388583 -1.446703  0.370446   \n",
       "\n",
       "        2371      2372      2373      2374      2375  Emotions  \n",
       "0   0.441149 -0.924505  0.232787  0.871313 -0.268860      fear  \n",
       "1   0.441149 -0.924505  0.232787  0.871313 -0.268860      fear  \n",
       "2   0.441149 -0.924505  0.232787  0.871313 -0.268860      fear  \n",
       "3   0.441149 -0.924505  0.232787  0.871313 -0.268860      fear  \n",
       "4   1.838805  0.072122  1.395948  0.976907  0.155367      fear  \n",
       "5   1.838805  0.072122  1.395948  0.976907  0.155367      fear  \n",
       "6   1.838805  0.072122  1.395948  0.976907  0.155367      fear  \n",
       "7   1.838805  0.072122  1.395948  0.976907  0.155367      fear  \n",
       "8  -0.171990  1.607917  0.942241 -0.708967  0.791900     happy  \n",
       "9   0.580537  1.258397  1.776845  0.134927  1.858365     happy  \n",
       "10  0.580537  1.258397  1.776845  0.134927  1.858365     happy  \n",
       "11  0.580537  1.258397  1.776845  0.134927  1.858365     happy  \n",
       "12  0.580537  1.258397  1.776845  0.134927  1.858365     happy  \n",
       "13  0.436404  0.832283  0.961930 -0.629323  2.220373     happy  \n",
       "14  0.436404  0.832283  0.961930 -0.629323  2.220373     happy  \n",
       "15  0.436404  0.832283  0.961930 -0.629323  2.220373     happy  \n",
       "16  0.436404  0.832283  0.961930 -0.629323  2.220373     happy  \n",
       "17  0.798398  0.611098  0.780687  0.693781  0.961922     happy  \n",
       "18  0.798398  0.611098  0.780687  0.693781  0.961922     happy  \n",
       "19  0.798398  0.611098  0.780687  0.693781  0.961922     happy  \n",
       "20  0.798398  0.611098  0.780687  0.693781  0.961922     happy  \n",
       "21  0.065740 -0.704857  1.735322  0.460800 -0.088769       sad  \n",
       "22  0.065740 -0.704857  1.735322  0.460800 -0.088769       sad  \n",
       "23  0.065740 -0.704857  1.735322  0.460800 -0.088769       sad  \n",
       "24  0.065740 -0.704857  1.735322  0.460800 -0.088769       sad  \n",
       "25  1.296568 -0.441104  2.673223 -0.103134 -0.915359       sad  \n",
       "26  1.296568 -0.441104  2.673223 -0.103134 -0.915359       sad  \n",
       "27  1.296568 -0.441104  2.673223 -0.103134 -0.915359       sad  \n",
       "28  1.296568 -0.441104  2.673223 -0.103134 -0.915359       sad  \n",
       "\n",
       "[29 rows x 2377 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\Alkostantini\\OneDrive - reutlingen-university.de\\git\\Prosody_Emotion-Recognition\\Models\\df_Database.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
