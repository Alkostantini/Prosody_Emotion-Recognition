{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align: center; font-size: 36px; color: #3498db; font-weight: bold;\">Prosody Application</h1>\n",
    "## <h2 style=\"text-align: center; font-size: 28px; color: #2ecc71; font-weight: bold;\">Emotion Recognation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#@author: Eyad Alkostantini\n",
    "############################\n",
    "\n",
    "import os \n",
    "import pickle\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import wave\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Cloud Folder\n",
    "if not os.path.exists(\"Models\"):\n",
    "    import gdown\n",
    "    folder_url =r\"https://drive.google.com/drive/folders/1-3955kcRmnJ73xFE8yZbFNIqkZ1tiyY1?usp=sharing\" \n",
    "    gdown.download_folder(folder_url)\n",
    "##########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosody Model has been loaded\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# loding the model, weights, scaler and encoder\n",
    "###############################################\n",
    "\n",
    "prosody_model = tf.keras.models.load_model(r'./Models/Prosody_Model.keras')\n",
    "print (\"Prosody Model has been loaded\")\n",
    "\n",
    "# loding the Scaler\n",
    "with open(r\"./Models/Prosody_Scaler.pickle\", 'rb') as f:\n",
    "    prosody_scaler = pickle.load(f)\n",
    "\n",
    "# loding the Encoder    \n",
    "with open(r\"./Models/Prosody_Encoder.pickle\", 'rb') as f:\n",
    "    prosody_Encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# geting the features from the voice\n",
    "#####################################\n",
    "\n",
    "## ZCR: Zero Crossing Rate: The rate of sign changes of the signal during the duration of a particular frame\n",
    "def zcr(data, frame_length, hop_length):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "## RMS: root mean square value\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "## MFCC: Mel Frequency Cepstral Coefficients form a cepstral representation where the frequency bands are not linear but distributed according to the mel-scale\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "## Extraxing the features\n",
    "def extract_features(data, sr=22050, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                        ))\n",
    "    return result\n",
    "\n",
    "###############################\n",
    "# features extraxtion function\n",
    "###############################\n",
    "def get_features(path):\n",
    "    data, sr= librosa.load(path, duration=2.5, offset=0) # Extract for 2.5 seconds\n",
    "    result=extract_features(data)\n",
    "    result=np.array(result)\n",
    "    result = np.reshape(result, (1, -1))\n",
    "    result = prosody_scaler.transform(result)  # Scaler\n",
    "    return result\n",
    "\n",
    "######################\n",
    "# Prediction function\n",
    "######################\n",
    "def prediction(path):\n",
    "    result = get_features(path)\n",
    "    prediction = prosody_model.predict(result)\n",
    "    y_prediction = prosody_Encoder.inverse_transform(prediction.reshape(1, -1))\n",
    "    predicted_class = y_prediction[0][0]\n",
    "    # class probabilities\n",
    "    predicted_probs = prediction[0]\n",
    "    # class names from encoder\n",
    "    class_names = prosody_Encoder.categories_[0]\n",
    "    ''''\n",
    "    # Print predicted class and probabilities for all classes\n",
    "    print(\"Predictions for all classes:\")\n",
    "    for label, prob in zip(class_names, predicted_probs):\n",
    "        print(f\"{label}: {prob*100:.2f}%\")\n",
    "    '''\n",
    "    return predicted_class, predicted_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 style=\"text-align: left; font-size: 28px; color: #2ecc71; font-weight: bold;\">Real-Time Prediction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Listening...\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Listening...\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "import time  # Import time module for sleep function\n",
    "\n",
    "#######################\n",
    "# Real-Time prediction\n",
    "#######################\n",
    "\n",
    "class EmotionPlotter:\n",
    "    def __init__(self, root, update_callback):\n",
    "        self.root = root\n",
    "        self.root.title(\"Emotion Prediction\")\n",
    "        self.update_callback = update_callback\n",
    "        self.class_names = ['Noise', 'angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.ax.set_title('Emotion Prediction')\n",
    "        self.ax.set_xlabel('Emotion')\n",
    "        self.ax.set_ylabel('Probability (%)')\n",
    "        self.ax.set_ylim(0, 100)\n",
    "        self.ax.set_xticks(np.arange(len(self.class_names)))\n",
    "        self.ax.set_xticklabels(self.class_names, rotation=45)\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.root)\n",
    "        self.canvas.draw()\n",
    "        self.canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "        #########################\n",
    "        # Recording configuration\n",
    "        #########################\n",
    "        self.RECORD_SECONDS = 2.5  # recording duration\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 44100\n",
    "        self.CHUNK = 1024\n",
    "        self.CHUNK_SIZE = 1024\n",
    "        self.OUTPUT_FILE = \"recorded_audio.wav\"\n",
    "        ########################\n",
    "        # start button\n",
    "        ########################\n",
    "        self.start_button = tk.Button(self.root, text=\"Start Recording\", command=self.start_visualization, font=('Helvetica', 14))\n",
    "        self.start_button.pack(side=tk.TOP, pady=10)\n",
    "        self.visualizing = False                 # track of visualization state\n",
    "\n",
    "        \n",
    "    def start_visualization(self):\n",
    "        if not self.visualizing:\n",
    "            self.visualizing = True\n",
    "            self.start_button['state'] = tk.DISABLED\n",
    "            self.update_loop()\n",
    "        \n",
    "    def update_loop(self):\n",
    "        ########################\n",
    "        # Start recording audio\n",
    "        ########################\n",
    "        self.update_gui_text(\"Recording in Progress...\")\n",
    "        print(\"Listening...\")\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RATE, input=True, frames_per_buffer=self.CHUNK)\n",
    "        frames = []\n",
    "        # Recording \n",
    "        for i in range(0, int(self.RATE / self.CHUNK_SIZE * self.RECORD_SECONDS)):\n",
    "            data = stream.read(self.CHUNK_SIZE)\n",
    "            frames.append(data)\n",
    "        # Stop recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        # Saving audio\n",
    "        with wave.open(self.OUTPUT_FILE, 'wb') as wf:\n",
    "            wf.setnchannels(self.CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(self.FORMAT))\n",
    "            wf.setframerate(self.RATE)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "\n",
    "        ####################\n",
    "        # Perform prediction\n",
    "        ####################\n",
    "        self.update_gui_text(\"Start Recording\")\n",
    "        predicted_class, predicted_probs = prediction(self.OUTPUT_FILE)\n",
    "        # callback\n",
    "        self.update_callback(self, predicted_class, predicted_probs)\n",
    "        # Reset visualization\n",
    "        self.visualizing = False\n",
    "        self.start_button['state'] = tk.NORMAL\n",
    "\n",
    "    def update_gui_text(self, text):\n",
    "        self.start_button.config(text=text)\n",
    "        self.root.update()\n",
    "\n",
    "    ########################\n",
    "    # Update Plot\n",
    "    ########################\n",
    "    def update_plot(self, predicted_probs):\n",
    "        self.ax.clear()\n",
    "        bars = self.ax.bar(self.class_names, predicted_probs * 100, color='blue')\n",
    "        self.ax.set_title('Emotion Prediction')\n",
    "        self.ax.set_xlabel('Emotion')\n",
    "        self.ax.set_ylabel('Probability (%)')\n",
    "        self.ax.set_ylim(0, 100)\n",
    "        self.ax.set_xticks(np.arange(len(self.class_names)))\n",
    "        self.ax.set_xticklabels(self.class_names, rotation=45)\n",
    "        for i, bar in enumerate(bars):\n",
    "            self.ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{predicted_probs[i]*100:.2f}%', ha='center', va='bottom')\n",
    "        self.canvas.draw()\n",
    "\n",
    "def visualize_emotion_prediction(plotter, predicted_class, predicted_probs):\n",
    "    plotter.update_plot(predicted_probs)\n",
    "\n",
    "\n",
    "# callback function\n",
    "root = tk.Tk() #root window\n",
    "plotter = EmotionPlotter(root, visualize_emotion_prediction)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
